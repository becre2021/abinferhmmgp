{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torch.da\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../PYTORCH_GP/')\n",
    "from PYTORCH_GP.models.ssgpr_reparametrization import ssgpr_amoritized_reparametrization_sm as ssgpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './dataset/Validation/Synthesis8_10/'\n",
    "filename = 'SinCos_state_8_8'\n",
    "formatted = '.mat'\n",
    "Synthetic = sio.loadmat(data_path + filename + formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class custom_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,x,y):\n",
    "        self.data_len = x_train.shape[1]\n",
    "        self.to_tensor = torch.DoubleTensor\n",
    "        self._transform_list(x,y)\n",
    "        \n",
    "    def _transform_list(self,x,y):        \n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        for i_th in range(x.shape[1]):\n",
    "            x_list.append(x[:,i_th])\n",
    "            y_list.append(y[:,i_th])\n",
    "            \n",
    "        self.x = x_list\n",
    "        self.y = y_list\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        x_ith = self.x[index]\n",
    "        y_ith = self.y[index]\n",
    "        return (self.to_tensor(x_ith),self.to_tensor(y_ith))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Synthetic['zfull']\n",
    "x = Synthetic['xfull']\n",
    "y = Synthetic['yfull']\n",
    "\n",
    "num_train = 50\n",
    "x_train,x_test = x[:,:num_train],x[:,num_train:2*num_train]\n",
    "y_train,y_test = y[:,:num_train],y[:,num_train:2*num_train]\n",
    "\n",
    "train_set = custom_dataset(x_train,y_train)\n",
    "test_set = custom_dataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_set, batch_size = 50, shuffle = False, num_workers = 2)\n",
    "testloader = DataLoader(test_set, batch_size = 2, shuffle = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[0.0000e+00, 9.7420e-02, 2.0475e-01,  ..., 4.6901e+00, 4.8015e+00,\n",
      "         4.9162e+00],\n",
      "        [5.0000e+00, 5.0986e+00, 5.1951e+00,  ..., 9.7038e+00, 9.7958e+00,\n",
      "         9.8978e+00],\n",
      "        [1.0000e+01, 1.0101e+01, 1.0202e+01,  ..., 1.4707e+01, 1.4800e+01,\n",
      "         1.4898e+01],\n",
      "        ...,\n",
      "        [2.3500e+02, 2.3510e+02, 2.3520e+02,  ..., 2.3970e+02, 2.3980e+02,\n",
      "         2.3990e+02],\n",
      "        [2.4000e+02, 2.4011e+02, 2.4021e+02,  ..., 2.4471e+02, 2.4480e+02,\n",
      "         2.4490e+02],\n",
      "        [2.4500e+02, 2.4510e+02, 2.4520e+02,  ..., 2.4970e+02, 2.4981e+02,\n",
      "         2.4989e+02]], dtype=torch.float64) tensor([[ 0.8886, -1.4824,  1.5944,  ..., -0.5368,  0.5691, -0.6605],\n",
      "        [-0.4855,  0.9193,  1.8726,  ...,  0.5232, -0.9675, -1.8995],\n",
      "        [ 0.4071,  0.3653, -1.0316,  ...,  0.2718, -0.5079,  0.7401],\n",
      "        ...,\n",
      "        [-0.7193, -1.4005, -0.6660,  ...,  2.0909,  0.9162, -0.0033],\n",
      "        [-0.7267,  1.4164,  0.6153,  ..., -1.4984,  0.1493,  1.4022],\n",
      "        [-0.8819,  1.4695, -1.5936,  ...,  1.7176, -1.7263,  0.8220]],\n",
      "       dtype=torch.float64)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, (x_i, y_i) in enumerate(trainloader):\n",
    "    x_i = Variable(x_i)\n",
    "    y_i = Variable(y_i)\n",
    "    print(i)\n",
    "    print(x_i,y_i)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_state = 3\n",
    "#ssgpr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_vbem(model_cls):\n",
    "    \n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-55-6be1b1c7c1d9>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-55-6be1b1c7c1d9>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    def __init__(self,)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class GP_Emission(torch.nn):\n",
    "    \n",
    "    def __init__(self,)\n",
    "    def _update_hyp_param(self):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.ones([3,3])).view(3,-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Module,Parameter\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "\n",
    "#class model(Module)\n",
    "\n",
    "class HMM_GP(Module):\n",
    "    \n",
    "    def __init__(self,emission_cls,num_hidden_state):\n",
    "        super(HMM_GP,self).__init__()\n",
    "        \n",
    "        self.emission_model = emission_cls\n",
    "        self.num_hidden_state = num_hidden_state        \n",
    "        self.emission_cls = emission_cls\n",
    "        self._init_param()\n",
    "    \n",
    "    def _init_param(self):\n",
    "        self.var_param_A = torch.from_numpy(np.ones([num_hidden_state,num_hidden_state]))\n",
    "        self.var_param_pi = torch.from_numpy(np.ones([num_hidden_state,1]))\n",
    "        self.var_param_A = self.var_param_A.div(self.var_param_A.sum(dim = 1))\n",
    "        self.var_param_pi = self.var_param_pi.div(self.var_param_pi.sum(dim = 1))\n",
    "    \n",
    "        self.var_prior_A = torch.from_numpy(np.ones([num_hidden_state,num_hidden_state]))\n",
    "        self.var_prior_pi = torch.from_numpy(np.ones([num_hidden_state,1])) \n",
    "        return \n",
    "    \n",
    "    \n",
    "    def _calc_obs_prob(self,batch_x,batch_y):\n",
    "        \n",
    "        batch_emission_prob = np.zeros(self.num_hidden_state,batch_y.shape[1])        \n",
    "        for i_th,(i_th_batch_x,i_th_batch_y) in enumerate(zip(batch_x,batch_y)) :\n",
    "            for j_th in np.arange(self.num_hidden_state):\n",
    "                batch_emission_prob[j_th,i_th] = self.emission_model._get_emission_prob(i_th_batch_x,\n",
    "                                                                                        i_th_batch_y)\n",
    "            \n",
    "        return batch_emission_prob\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _update_var_param(self):\n",
    "        return\n",
    "        \n",
    "    def _update_var_nat_param(self):\n",
    "        return\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMM  = HMM_GP(emission_cls = None,num_hidden_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3333, 0.3333, 0.3333],\n",
       "        [0.3333, 0.3333, 0.3333],\n",
       "        [0.3333, 0.3333, 0.3333]], dtype=torch.float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HMM.var_param_A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
