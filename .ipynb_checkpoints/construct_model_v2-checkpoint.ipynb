{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../')\n",
    "sys.path.append('./../PYTORCH_GP/')\n",
    "# from PYTORCH_GP.models.ssgpr_reparametrization import ssgpr_amoritized_reparametrization_sm as ssgpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import model\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import likelihoods\n",
    "from mean_function import zero_function\n",
    "from time import time\n",
    "TensorType = torch.DoubleTensor\n",
    "numpy_Type = np.float64\n",
    "\n",
    "\n",
    "class gpmodel(model):\n",
    "    def __init__(self, x, y, kernel, meanfunction, likelihood , cuda_option  , name = 'gp'):\n",
    "        super(gpmodel,self).__init__()\n",
    "        self.kernel = kernel\n",
    "        self.likelihood = likelihoods.Gaussian(variance = 0.1,cuda_option = cuda_option) if likelihood == None else likelihood\n",
    "        self.meanfunction = zero_function(cuda_option) if meanfunction == None else meanfunction(cuda_option)\n",
    "        self.tensor_type = torch.cuda.DoubleTensor if cuda_option == True else torch.DoubleTensor\n",
    "        self.zitter = 1e-8\n",
    "        self._check_observations(x,y)\n",
    "        self.__class__.__name__ = name\n",
    "\n",
    "    def _check_observations(self,x,y):\n",
    "                    \n",
    "        self.x = torch.from_numpy(x).type(self.tensor_type) if x != None else None\n",
    "        self.y = torch.from_numpy(x).type(self.tensor_type) if y != None else None\n",
    "        return\n",
    "\n",
    "    def compute_loss(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _compute_Kxx(self,x):\n",
    "        num_input = x.shape[0]\n",
    "        return self.kernel.K(x) + (self.likelihood.variance.transform() + self.zitter).expand(num_input, num_input).diag().diag()\n",
    "        #return self.kernel.K(x)\n",
    "\n",
    "\n",
    "    def _compute_Kxx_diag(self,x):\n",
    "        #return self._compute_Kxx(x).diag()\n",
    "        return self._compute_Kxx(x).diag()\n",
    "    \n",
    "    def _compute_Kxs(self,x,xstar):\n",
    "        num_input = x.shape[0]\n",
    "        return self.kernel.K(x,xstar)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from model import Param\n",
    "from models.gpmodel import gpmodel\n",
    "from function import trtrs, cholesky, lt_log_determinant\n",
    "from kernels.RBF_kernel import RBF\n",
    "from mean_function import zero_function\n",
    "import likelihoods\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "TensorType = torch.DoubleTensor\n",
    "\n",
    "\n",
    "class gpr(gpmodel):\n",
    "\n",
    "    def __init__(self, inputs, outputs, kernel, mean_function = None, likelihood = None, cuda_option = None):\n",
    "        # input_obs = # training_data x # data_dim\n",
    "        # output_obs = # training_data x 1\n",
    "        super(gpr,self).__init__(inputs, outputs, kernel, mean_function, likelihood, cuda_option,name= 'gpr')\n",
    "\n",
    "        \n",
    "    def _check_observations(self,x,y):                    \n",
    "        self.x = torch.from_numpy(x).type(self.tensor_type) if x != None else None\n",
    "        self.y = torch.from_numpy(x).type(self.tensor_type) if y != None else None\n",
    "        return\n",
    "        \n",
    "    def compute_loss(self, batch_x, batch_y ):\n",
    "        #batch_x, batch_y = self._check_observations(batch_x,batch_y)\n",
    "        num_input,dim_output = batch_y.shape\n",
    "        # made by me\n",
    "        L = cholesky(self._compute_Kxx(batch_x))\n",
    "        alpha = trtrs(L, batch_y)\n",
    "        loss = 0.5 * alpha.pow(2).sum() + lt_log_determinant(L) + 0.5 * num_input * np.log(2.0 * np.pi)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def _get_log_prob(self, batch_x, batch_y ) : \n",
    "        return -self.compute_loss(batch_x, batch_y)\n",
    "\n",
    "    \n",
    "    def _predict(self, inputs_new, diag):\n",
    "        if isinstance(inputs_new, np.ndarray):\n",
    "            inputs_new = torch.Tensor(inputs_new).type(self.tensor_type)\n",
    "        kxx = self._compute_Kxx(self.x)\n",
    "        k_xs = self._compute_Kxs(self.x,inputs_new)\n",
    "        # reference_code\n",
    "        L = cholesky(kxx)\n",
    "        A = trtrs(L, k_xs)\n",
    "        V = trtrs(L, self.y)\n",
    "        mean_f = torch.mm(torch.transpose(A, 0, 1), V)        \n",
    "        if self.meanfunction is not None:\n",
    "            mean_f += self.meanfunction(inputs_new,self.y.shape[1])            \n",
    "        A = trtrs(L, k_xs)\n",
    "        if diag:\n",
    "            var_f1 = self.kernel.K_diag(inputs_new)\n",
    "            var_f2 = torch.sum(A * A, 0)\n",
    "            return mean_f, (var_f1 - var_f2).reshape(-1,1)\n",
    "        else:\n",
    "            var_f1 = self.kernel.K(inputs_new)\n",
    "            var_f2 = torch.mm(A.t(), A)\n",
    "            return mean_f, (var_f1 - var_f2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './dataset/Validation/Synthesis8_10/'\n",
    "filename = 'SinCos_state_8_2'\n",
    "formatted = '.mat'\n",
    "Synthetic = sio.loadmat(data_path + filename + formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class custom_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,x,y):\n",
    "        self.data_len = x_train.shape[1]\n",
    "        self.to_tensor = torch.DoubleTensor\n",
    "        self._transform_list(x,y)\n",
    "        \n",
    "    def _transform_list(self,x,y):        \n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        for i_th in range(x.shape[1]):\n",
    "            x_list.append(x[:,i_th])\n",
    "            y_list.append(y[:,i_th])\n",
    "            \n",
    "        self.x = x_list\n",
    "        self.y = y_list\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        x_ith = self.x[index]\n",
    "        y_ith = self.y[index]\n",
    "        return (self.to_tensor(x_ith),self.to_tensor(y_ith))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Synthetic['zfull']\n",
    "x = Synthetic['xfull']\n",
    "y = Synthetic['yfull']\n",
    "num_train = 50\n",
    "x_train,x_test = x[:,:num_train],x[:,num_train:2*num_train]\n",
    "y_train,y_test = y[:,:num_train],y[:,num_train:2*num_train]\n",
    "z_train,z_test = z[:,:num_train],z[:,num_train:2*num_train]\n",
    "train_set = custom_dataset(x_train,y_train)\n",
    "test_set = custom_dataset(x_test,y_test)\n",
    "\n",
    "z_train = z_train[0,:]-1\n",
    "z_tets = z_test[0,:]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_set, batch_size = 1, shuffle = False, num_workers = 2)\n",
    "#testloader = DataLoader(test_set, batch_size = 1, shuffle = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def _init_param_emission_model(trainloader , maximal_hidden_state,top_Q,init_std) : \n",
    "    psd_list = []\n",
    "    freq_list = []\n",
    "    for i, (x_i, y_i) in enumerate(trainloader):\n",
    "        freqs,psd = signal.welch(y_i.reshape(1, -1).squeeze(), fs=int(1 / (x_i[0,1] - x_i[0,0])), nperseg=y_i.squeeze().shape[0])\n",
    "        psd_list.append(psd/psd.sum())\n",
    "    psd_list = np.asarray(psd_list)\n",
    "\n",
    "    param_list_dict = []\n",
    "    Kmeans_instance = KMeans(n_clusters = maximal_hidden_state, random_state = 0).fit(psd_list)\n",
    "    for j_th,j_th_centers in enumerate(Kmeans_instance.cluster_centers_):\n",
    "        #print(j_th_centers)\n",
    "        A = np.argsort(-j_th_centers)[:top_Q]\n",
    "        param_list_dict.append({'num_Q' : top_Q,\n",
    "                                'init_pi' : j_th_centers[A] , \n",
    "                                'init_mu' : freqs[A] ,\n",
    "                                'init_std' :init_std*np.random.rand(freqs[A].shape[0]) \n",
    "                               })\n",
    "    return param_list_dict , Kmeans_instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_Q = 3\n",
    "init_std = 0.1\n",
    "maximal_hidden_state = 5\n",
    "param_list_dict,_ = _init_param_emission_model(trainloader , maximal_hidden_state,top_Q,init_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernels.SM_kernel import SM\n",
    "\n",
    "def _make_gp_emission(model_name,x_train,y_train,param_dict):\n",
    "    input_dim = 1\n",
    "    cuda_option = True\n",
    "    Kern = SM(param_dict['num_Q'], input_dim,\n",
    "              param_dict['init_pi'],\n",
    "              param_dict['init_mu'],\n",
    "              param_dict['init_std'],\n",
    "              ARD=True,\n",
    "              cuda_option= cuda_option)\n",
    "\n",
    "    if model_name == 'gpr_sm':\n",
    "        model_gpr = gpr(x_train, y_train,\n",
    "                        Kern,\n",
    "                        mean_function=None,\n",
    "                        likelihood=None,\n",
    "                        cuda_option= cuda_option)\n",
    "\n",
    "        return model_gpr\n",
    "\n",
    "    if model_name == 'ssgpr_reg':\n",
    "        model_ssgpr_reg = ssgpr_amoritized_reparametrization_regulaizer(x_train, y_train,\n",
    "                                                                        num_sample,\n",
    "                                                                        param_dict,\n",
    "                                                                        cuda_option= cuda_option)\n",
    "\n",
    "        return model_ssgpr_reg\n",
    "\n",
    "\n",
    "def _construct_emission_model(model_name,param_list_dict):\n",
    "    emission_model_list = []\n",
    "    for i_th_param_dict in param_list_dict:\n",
    "        emission_model_list.append(_make_gp_emission(model_name, None, None,i_th_param_dict))\n",
    "    return emission_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpr_sm'\n",
    "emission_model_list = _construct_emission_model(model_name,param_list_dict)\n",
    "#emission_model_list[0],emission_model_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Module,Parameter\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class HMM_EmissionGP(Module):    \n",
    "    def __init__(self,emission_model_list = None,num_hidden_state = None):\n",
    "        super(HMM_EmissionGP,self).__init__()        \n",
    "        self.num_hidden_state = num_hidden_state        \n",
    "        self.emission_model_list = emission_model_list\n",
    "        self.lr_A = 0.01\n",
    "        self.lr_pi = 0.01\n",
    "        self.lr_emission_hyp = .005        \n",
    "        self.num_batch = 1\n",
    "        self.full_length= 50 \n",
    "        self.batch_length = 50\n",
    "        \n",
    "        \n",
    "        self._init_param()\n",
    "    \n",
    "    def _init_param(self):\n",
    "        # intilaize variational param\n",
    "        self.prior_A = torch.from_numpy(np.ones([self.num_hidden_state,1]))\n",
    "        self.prior_pi = torch.from_numpy(np.ones([self.num_hidden_state,1])) \n",
    "        self.var_param_A = self.prior_A.repeat(1,self.num_hidden_state)\n",
    "        self.var_param_pi = self.prior_pi\n",
    "\n",
    "        self.sample_factor_A = (self.full_length - self.batch_length + 1)/(self.batch_length - 1)\n",
    "        self.sample_factor_pi = 1 \n",
    "        self.sample_factor_emission = (self.full_length - self.batch_length + 1)/(self.batch_length)\n",
    "        \n",
    "        self.full_param_list = []\n",
    "        for j_th_emission in  self.emission_model_list:\n",
    "            for i_th_parameters in j_th_emission.parameters():\n",
    "                self.full_param_list.append(i_th_parameters)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.full_param_list,\n",
    "                                          lr= self.lr_emission_hyp,\n",
    "                                          betas=(0.9, 0.99),\n",
    "                                          eps=1e-08,\n",
    "                                          weight_decay=0.0)\n",
    "                \n",
    "        return \n",
    "    \n",
    "    \n",
    "    def _run_Estep(self, batch_x, batch_y):\n",
    "        batch_log_obs_prob = self._calc_obs_prob(batch_x,batch_y)\n",
    "        A_star = torch.digamma( self.var_param_A ) - torch.digamma( self.var_param_A.sum(dim =1,keepdim = True).repeat(1,self.num_hidden_state) )\n",
    "        A_star.exp_()\n",
    "        pi_star = torch.digamma( self.var_param_pi ) - torch.digamma(self.var_param_pi.sum());\n",
    "        pi_star.exp_()       \n",
    "        #return A_star,pi_star            \n",
    "        log_gamma,log_qsi,log_C,log_lik = self._log_forward_backward( batch_log_obs_prob, pi_star , A_star)\n",
    "        gamma,qsi = self._log_to_origin_scale(log_gamma,log_qsi)        \n",
    "        return gamma, qsi ,batch_log_obs_prob\n",
    "\n",
    "\n",
    "    def _run_Mstep(self,gamma,qsi,batch_log_obs,iter_hyp):\n",
    "        self._update_var_param_A(qsi)        \n",
    "        self._update_var_param_pi(gamma)        \n",
    "        for i in range(iter_hyp):\n",
    "            self._update_hyp_param_emission_model(batch_log_obs,gamma)\n",
    "        return\n",
    "        \n",
    "    \n",
    "    def _run_filtering(self,batch_x, batch_y):\n",
    "        batch_log_obs_prob = self._calc_obs_prob(batch_x,batch_y)\n",
    "        A_star = torch.digamma( self.var_param_A ) - torch.digamma( self.var_param_A.sum(dim =1,keepdim = True).repeat(1,self.num_hidden_state) )\n",
    "        A_star.exp_()\n",
    "        pi_star = torch.digamma( self.var_param_pi ) - torch.digamma(self.var_param_pi.sum());\n",
    "        pi_star.exp_()\n",
    "        log_alpha,_ = self._log_forward( batch_log_obs_prob, pi_star , A_star)\n",
    "        return log_alpha.argmax(dim = 0).data.numpy()        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _run_smoothing(self,batch_x, batch_y):\n",
    "        batch_log_obs_prob = self._calc_obs_prob(batch_x,batch_y)\n",
    "        A_star = torch.digamma( self.var_param_A ) - torch.digamma( self.var_param_A.sum(dim =1,keepdim = True).repeat(1,self.num_hidden_state) )\n",
    "        A_star.exp_()\n",
    "        pi_star = torch.digamma( self.var_param_pi ) - torch.digamma(self.var_param_pi.sum());\n",
    "        pi_star.exp_()       \n",
    "        #return A_star,pi_star            \n",
    "        log_gamma,log_qsi,log_C,log_lik = self._log_forward_backward( batch_log_obs_prob, pi_star , A_star)\n",
    "        return log_gamma.argmax(dim = 0).data.numpy()\n",
    "    \n",
    "    \n",
    "    def _calc_obs_prob(self, batch_x_list, batch_y_list):        \n",
    "        batch_log_emission_prob = torch.from_numpy(np.zeros( [self.num_hidden_state, len(batch_x_list)] ))       \n",
    "        for i_th,(i_th_batch_x,i_th_batch_y) in enumerate(zip(batch_x_list, batch_y_list)) :\n",
    "                for j_th,j_th_emission_model in enumerate(self.emission_model_list):\n",
    "                    batch_log_emission_prob[j_th,i_th] = j_th_emission_model._get_log_prob(i_th_batch_x,i_th_batch_y)           \n",
    "        return batch_log_emission_prob\n",
    "    \n",
    "    \n",
    "    def _log_forward(self, log_batch_obs_prob, pi_star , A_star ):\n",
    "        _ , batch_seq_length = log_batch_obs_prob.shape\n",
    "        \n",
    "        log_A_star = A_star.log()\n",
    "        log_pi_star = pi_star.log()        \n",
    "        log_alpha = torch.from_numpy(np.zeros([self.num_hidden_state,batch_seq_length]))        \n",
    "        log_C = torch.from_numpy( np.zeros( [ batch_seq_length ] ) )\n",
    "        log_C[0] = torch.logsumexp( log_alpha[:,0:0+1] + log_pi_star , dim = 0)\n",
    "        log_alpha[:,0:0+1] = -log_C[0] + log_batch_obs_prob[:,0:0+1] + log_pi_star\n",
    "        \n",
    "        for i_th in range(1,batch_seq_length):    \n",
    "            temp_alpha = log_A_star + log_alpha[:,i_th-1:i_th] + log_batch_obs_prob[:,i_th:i_th+1]\n",
    "            log_C[i_th] = torch.logsumexp(temp_alpha.view(-1,1),dim = 0)            \n",
    "            for j_th in range(self.num_hidden_state):\n",
    "                temp_ji = log_alpha[:,i_th-1:i_th] + log_A_star[:,j_th:j_th+1]\n",
    "                log_alpha[j_th,i_th] = -log_C[i_th] + log_batch_obs_prob[j_th,i_th] + torch.logsumexp(temp_ji.view(-1,1),dim = 0)\n",
    "        \n",
    "        return log_alpha,log_C\n",
    "        \n",
    "    \n",
    "    def _log_backward(self, log_batch_obs_prob, A_star, log_C ):\n",
    "        _ , batch_seq_length = log_batch_obs_prob.shape\n",
    "        log_At_star = A_star.log().t()        \n",
    "        log_beta = torch.from_numpy(np.zeros([self.num_hidden_state,batch_seq_length]))        \n",
    "        for i_th in reversed(range(batch_seq_length - 1)):\n",
    "            for j_th in range(self.num_hidden_state):\n",
    "                temp_beta = log_beta[:,i_th+1:i_th+2] + log_batch_obs_prob[:,i_th+1:i_th+2] + log_At_star[:,j_th:j_th+1]\n",
    "                log_beta[j_th,i_th] = -log_C[i_th + 1] + torch.logsumexp(temp_beta.view(-1,1) , dim = 0)\n",
    "        return log_beta\n",
    "    \n",
    "    \n",
    "    def _log_forward_backward(self, log_batch_obs_prob, pi_star , A_star):\n",
    "        _ , batch_seq_length = log_batch_obs_prob.shape        \n",
    "        log_A_star = A_star.log()\n",
    "        log_pi_star = pi_star.log()        \n",
    "        log_alpha,log_C = self._log_forward( log_batch_obs_prob, pi_star , A_star)\n",
    "        log_beta = self._log_backward(log_batch_obs_prob, A_star, log_C )\n",
    "        log_gamma = log_alpha + log_beta\n",
    "        \n",
    "        log_qsi = torch.from_numpy(np.zeros([self.num_hidden_state,self.num_hidden_state,batch_seq_length]))\n",
    "        for i_th in range(1, batch_seq_length ):\n",
    "            log_qsi[:,:,i_th] = -log_C[i_th] + log_A_star + log_alpha[:,i_th:i_th+1]\n",
    "            log_qsi[:,:,i_th] += (log_beta[:,i_th:i_th+1] + log_batch_obs_prob[:,i_th:i_th+1]).t()\n",
    "        log_lik = log_C.sum()\n",
    "        return log_gamma,log_qsi,log_C,log_lik \n",
    "    \n",
    "\n",
    "    def _log_to_origin_scale(self,log_gamma,log_qsi):        \n",
    "        _,batch_seq_length = log_gamma.shape\n",
    "        for i_th in range(batch_seq_length):\n",
    "            log_gamma[:,i_th] = log_gamma[:,i_th] - log_gamma[:,i_th].max()    \n",
    "        gamma = log_gamma.exp()        \n",
    "        gamma = gamma.div(gamma.sum(dim = 0))\n",
    "        #qsi = log_qsi.exp()        \n",
    "        for i_th in range(batch_seq_length):\n",
    "            log_qsi[:,:,i_th] = log_qsi[:,:,i_th] - log_qsi[:,:,i_th].max(dim = 1,keepdim = True)[0]\n",
    "        qsi = log_qsi.exp()  \n",
    "        for i_th in range(batch_seq_length):\n",
    "            qsi[:,:,i_th].div(qsi[:,:,i_th].sum(dim = 1,keepdim = True))\n",
    "\n",
    "        return gamma,qsi\n",
    "    \n",
    "    \n",
    "    def _update_var_param_A(self,qsi):      \n",
    "        #qsi.sum(dim = 2, keepdim = True).shapsample\n",
    "        intermediate_A = self.sample_factor_A*qsi.sum(dim = 2, keepdim = False)\n",
    "        intermediate_A = self.prior_A.repeat(1,self.num_hidden_state) + (1/self.num_batch)*intermediate_A\n",
    "        self.var_param_A = (1 - self.lr_A)*self.var_param_A + self.lr_A*intermediate_A\n",
    "        return \n",
    "    \n",
    "    def _update_var_param_pi(self,gamma):     \n",
    "        intermediate_pi = self.sample_factor_pi*gamma[:,0:1]\n",
    "        intermediate_pi = self.prior_pi + (1/self.num_batch)*intermediate_pi\n",
    "        self.var_param_pi = (1 - self.lr_pi)*self.var_param_pi + self.lr_pi*intermediate_pi\n",
    "        return \n",
    "    \n",
    "    def _calc_intermediate_loss(self,batch_log_obs,gamma):\n",
    "        # positive\n",
    "        return self.sample_factor_emission*(batch_log_obs.mul(gamma.data)).sum()\n",
    "\n",
    "    \n",
    "    def _update_hyp_param_emission_model(self,batch_log_obs,gamma):\n",
    "        #loss = -(batch_log_obs.mul(gamma.data)).sum()\n",
    "        self.optimizer.zero_grad() \n",
    "        loss = -self._calc_intermediate_loss(batch_log_obs,gamma)\n",
    "        loss.backward(retain_graph = True)\n",
    "        self.optimizer.step() \n",
    "        torch.cuda.empty_cache()\n",
    "        return\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metric import *\n",
    "def _measure_metric(z_label,z_pred):\n",
    "    z_label = np.asarray(z_label,dtype = np.int32)\n",
    "\n",
    "    revised_list = get_map_pairs(z_label, z_pred)\n",
    "    revised_dict = {}\n",
    "    revised_cluster = []\n",
    "    for (i,j) in revised_list:\n",
    "        revised_dict.update({ j : i })        \n",
    "        #revised_dict.update({ i : j })\n",
    "    for j_th in z_pred:\n",
    "        #revised_cluster.append(revised_dict[j_th] )\n",
    "        try :\n",
    "            revised_cluster.append(revised_dict[j_th] )\n",
    "        except :\n",
    "            revised_cluster.append(-1.)\n",
    "            \n",
    "    revised_cluster = np.asarray(revised_cluster)\n",
    "    \n",
    "    return revised_dict,revised_cluster,z_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform_batchset(x,y,cuda_option):        \n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for i_th in range(x.shape[1]):\n",
    "        if cuda_option :\n",
    "            x_list.append(torch.from_numpy(x[:,i_th]).view(-1,1).cuda())\n",
    "            y_list.append(torch.from_numpy(y[:,i_th]).view(-1,1).cuda())\n",
    "        else  :       \n",
    "            x_list.append(torch.from_numpy(x[:,i_th]).view(-1,1))\n",
    "            y_list.append(torch.from_numpy(y[:,i_th]).view(-1,1))\n",
    "            \n",
    "            \n",
    "    return x_list,y_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _train_vbem(model_cls):\n",
    "#     return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_Q = 3\n",
    "init_std = 0.1\n",
    "maximal_hidden_state = 8\n",
    "param_list_dict,_ = _init_param_emission_model(trainloader , maximal_hidden_state,top_Q,init_std)\n",
    "\n",
    "model_name = 'gpr_sm'\n",
    "emission_model_list = _construct_emission_model(model_name,param_list_dict)\n",
    "#emission_model_list[0],emission_model_list[1]\n",
    "HMM_EmissionGP_SM  = HMM_EmissionGP(emission_model_list = emission_model_list,num_hidden_state = maximal_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HMM_EmissionGP_SM.var_param_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x,batch_y = _transform_batchset(x_train,y_train,True)\n",
    "#batch_x,batch_y = _transform_batchset(x_test,y_test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./../PYTORCH_GP/function.py:95: UserWarning: torch.potrf is deprecated in favour of torch.cholesky and will be removed in the next release. Please use torch.cholesky instead and note that the :attr:`upper` argument in torch.cholesky defaults to ``False``.\n",
      "  L = torch.potrf(A, upper=False)\n"
     ]
    }
   ],
   "source": [
    "z_pred = HMM_EmissionGP_SM._run_smoothing(batch_x,batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.7400, \t accuracy : 0.7400\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "revised_dict,z_pred_rev,z_label = _measure_metric(z_label,z_pred)\n",
    "#z_label,z_pred,z_pred_rev\n",
    "print('accuracy : %.4f, \\t accuracy : %.4f'%(accuracy(z_label,z_pred),accuracy(z_label,z_pred_rev)))\n",
    "\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.plot(z_label,'r.',label = 'label')\n",
    "#plt.plot(z_pred,'b.',label = 'estimate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (8,5))\n",
    "#plt.plot(z_label,'r.',label = 'label')\n",
    "plt.plot(z_pred_rev,'g.',label = 'estimate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_VBEM(model_cls,\n",
    "                batch_x,\n",
    "                batch_y,\n",
    "                num_iter,\n",
    "                num_iter_hyp):\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        gamma, qsi , batch_log_obs = model_cls._run_Estep(batch_x,batch_y)\n",
    "        #z_pred = gamma.argmax(dim = 0).data.numpy()\n",
    "        print('iter %d, batch_log_obs : %.4f '%(i + 1,batch_log_obs.sum().data))\n",
    "        #z_label = z_test\n",
    "        model_cls._run_Mstep(gamma,qsi,batch_log_obs,num_iter_hyp)\n",
    "        torch.cuda.empty_cache()\n",
    "        #print(HMM_EmissionGP_SM._calc_intermediate_loss(batch_log_obs,gamma).data)    \n",
    "    \n",
    "    return \n",
    "# iter_hyp = 10\n",
    "# for i in range(10):\n",
    "#     gamma, qsi , batch_log_obs = HMM_EmissionGP_SM._run_Estep(batch_x,batch_y)\n",
    "#     #z_pred = gamma.argmax(dim = 0).data.numpy()\n",
    "#     print('batch_log_obs : %.4f '%(batch_log_obs.sum().data))\n",
    "#     #z_label = z_test\n",
    "#     HMM_EmissionGP_SM._run_Mstep(gamma,qsi,batch_log_obs,iter_hyp)\n",
    "#     #print(HMM_EmissionGP_SM._calc_intermediate_loss(batch_log_obs,gamma).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1, batch_log_obs : -70142.6642 \n",
      "iter 2, batch_log_obs : -70536.3337 \n",
      "iter 3, batch_log_obs : -70781.9964 \n",
      "iter 4, batch_log_obs : -70976.8494 \n",
      "iter 5, batch_log_obs : -71050.8574 \n",
      "iter 6, batch_log_obs : -71141.4108 \n",
      "iter 7, batch_log_obs : -71272.3182 \n",
      "iter 8, batch_log_obs : -71419.8195 \n",
      "iter 9, batch_log_obs : -71532.1305 \n",
      "iter 10, batch_log_obs : -71595.3618 \n",
      "iter 11, batch_log_obs : -71611.3968 \n",
      "iter 12, batch_log_obs : -71590.5964 \n",
      "iter 13, batch_log_obs : -71556.2131 \n",
      "iter 14, batch_log_obs : -71523.8382 \n",
      "iter 15, batch_log_obs : -71481.8357 \n",
      "iter 16, batch_log_obs : -71414.6346 \n",
      "iter 17, batch_log_obs : -71305.8693 \n",
      "iter 18, batch_log_obs : -71163.0473 \n",
      "iter 19, batch_log_obs : -71030.7954 \n",
      "iter 20, batch_log_obs : -70993.9933 \n"
     ]
    }
   ],
   "source": [
    "_train_VBEM(HMM_EmissionGP_SM,\n",
    "            batch_x,\n",
    "            batch_y,\n",
    "            num_iter = 20,\n",
    "            num_iter_hyp = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pred2 = HMM_EmissionGP_SM._run_smoothing(batch_x,batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.7400, \t accuracy : 0.7400\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "revised_dict,z_pred_rev2,z_label = _measure_metric(z_label,z_pred2)\n",
    "#z_label,z_pred,z_pred_rev\n",
    "print('accuracy : %.4f, \\t accuracy : %.4f'%(accuracy(z_label,z_pred2),accuracy(z_label,z_pred_rev2)))\n",
    "\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.plot(z_label,'r.',label = 'label')\n",
    "#plt.plot(z_pred,'b.',label = 'estimate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (8,5))\n",
    "#plt.plot(z_label,'r.',label = 'label')\n",
    "plt.plot(z_pred_rev,'g.',label = 'estimate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_update\n",
    "# pi_update\n",
    "# qsi normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %temp_var_param_pi = obj.prior_pi + Gamma(:,1);\n",
    "# %temp_var_param_A = repmat(obj.prior_A ,[obj.state_num,1]) + sum(Ksi,3);\n",
    "# intermediate_pi = zeros(model_class.state_num,1);\n",
    "# intermediate_A = zeros(model_class.state_num);\n",
    "# sample_factor_A = ( size(xtrain,2) - model_class.sampled_length + 1)/(model_class.sampled_length - 1);\n",
    "\n",
    "# for jj = 1:model_class.batch_num\n",
    "#     intermediate_pi = intermediate_pi + Gamma{jj}(:,1);\n",
    "#     intermediate_A = intermediate_A + sample_factor_A*sum(Ksi{batch_iter},3);\n",
    "# end\n",
    "# intermediate_pi = model_class.prior_pi + (1/model_class.batch_num)*intermediate_pi;\n",
    "# intermediate_A = repmat(model_class.prior_A,[model_class.state_num,1]) + (1/model_class.batch_num)*intermediate_A;\n",
    "\n",
    "# temp_var_param_pi = (1 - lrate2)*temp_var_param_pi + lrate2*intermediate_pi;\n",
    "# temp_var_param_A = (1 - lrate2)*temp_var_param_A + lrate2*intermediate_A;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_list = []\n",
    "# for j_th_emission in  HMM_EmissionGP_SM.emission_model_list:\n",
    "#     for i_th_parameters in j_th_emission.parameters():\n",
    "#         param_list.append(i_th_parameters)\n",
    "# optimizer = torch.optim.SGD(param_list, lr = 0.1) \n",
    "# #param_list,optimizer\n",
    "\n",
    "# def _calculate_intermediate_loss(batch_log_obs,gamma):\n",
    "#     return -(batch_log_obs.mul(gamma.data)).sum()\n",
    "\n",
    "# loss = _calculate_intermediate_loss(batch_log_obs,gamma)\n",
    "# loss.backward(retain_graph = True)\n",
    "# optimizer.zero_grad() \n",
    "# optimizer.step() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation metrics\n",
    "# labels = np.array([1,1,1,1,1,1,3,3,3,3,3,3,2,2,2,2,2])\n",
    "# gt = np.array([1,1,1,1,1,2,1,2,2,2,2,3,1,1,3,3,3])\n",
    "# print (accuracy(gt, labels)) #0.7059\n",
    "# print (f_measure(gt,labels)) #0.4762\n",
    "# print (normalized_mutual_info_score(gt, labels)) #0.365\n",
    "# print (purity(gt,labels)) #0.7059\n",
    "# print (random_index(gt,labels)) #0.6765\n",
    "\n",
    "# labels = np.array([2,2,1,1,1,1,1,2])\n",
    "# gt = np.array([1,1,2,2,3,3,3,3])\n",
    "# print accuracy(gt, labels) #0.625\n",
    "# print f_measure(gt,labels) #0.4762\n",
    "# print normalized_mutual_info_score(gt, labels) #0.4587\n",
    "# print purity(gt,labels) #0.875\n",
    "# print random_index(gt,labels) #0.6071\n",
    "\n",
    "# print \"End\"\n",
    "#print (random_index(c_gt,c_labels)) #0.6765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_alpha,log_C = HMM._log_forward(log_obs_prob, pi_star , A_star )\n",
    "# log_beta = HMM._log_backward( log_obs_prob, A_star , log_C )\n",
    "# log_gamma,log_qsi,log_C,log_lik  = HMM._log_forward_backward( log_obs_prob, pi_star , A_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gamma,qsi = HMM._log_to_origin_scale(log_gamma,log_qsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
